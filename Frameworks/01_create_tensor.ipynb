{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1b9107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/gyeongdeokpark/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "    - torchaudio\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pytorch-2.0.0              |          py3.9_0        76.4 MB  pytorch\n",
      "    torchaudio-2.0.0           |         py39_cpu         6.6 MB  pytorch\n",
      "    torchvision-0.15.0         |         py39_cpu         6.4 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        89.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ffmpeg             pytorch/osx-64::ffmpeg-4.3-h0a44026_0 None\n",
      "  gnutls             pkgs/main/osx-64::gnutls-3.6.15-hed9c0bf_0 None\n",
      "  lame               pkgs/main/osx-64::lame-3.100-h1de35cc_0 None\n",
      "  libtasn1           pkgs/main/osx-64::libtasn1-4.16.0-h9ed2024_0 None\n",
      "  nettle             pkgs/main/osx-64::nettle-3.7.3-h230ac6f_1 None\n",
      "  openh264           pkgs/main/osx-64::openh264-2.1.1-h8346a28_0 None\n",
      "  pytorch            pytorch/osx-64::pytorch-2.0.0-py3.9_0 None\n",
      "  torchaudio         pytorch/osx-64::torchaudio-2.0.0-py39_cpu None\n",
      "  torchvision        pytorch/osx-64::torchvision-0.15.0-py39_cpu None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "torchvision-0.15.0   | 6.4 MB    | ##################################### | 100% \n",
      "torchaudio-2.0.0     | 6.6 MB    | ##################################### | 100% \n",
      "pytorch-2.0.0        | 76.4 MB   | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#conda install pytorch torchvision torchaudio -c pytorch -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ea8d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# pytorch import \n",
    "import torch\n",
    "# check version\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674541d",
   "metadata": {},
   "source": [
    "### Scala: ZeroDimension Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5c15570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0 ()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data0 = np.array(10)\n",
    "print(data0, data0.ndim, data0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8328da",
   "metadata": {},
   "source": [
    "### Vector: One Dimension Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0efd8f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.]) 1 torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([1, 2])\n",
    "print(data1, data1.dim(), data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d110e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.]) 1 torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor(3)\n",
    "print(data1, data1.dim(), data1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392248ca",
   "metadata": {},
   "source": [
    "### Matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d56c65",
   "metadata": {},
   "source": [
    "#### 2D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bcb69ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.6514e-01, 7.6482e-01, 7.1869e-01, 6.8475e-01, 8.4244e-01, 1.8723e-01,\n",
      "         5.8109e-01, 2.1734e-01, 7.3604e-01],\n",
      "        [1.6300e-01, 3.9504e-01, 3.0982e-01, 6.8726e-01, 3.7568e-03, 4.1115e-01,\n",
      "         4.1774e-01, 5.7040e-01, 3.3384e-01],\n",
      "        [2.0237e-03, 9.3498e-03, 4.5884e-04, 9.3843e-01, 3.8153e-02, 3.4664e-01,\n",
      "         2.0660e-01, 6.2135e-01, 8.2283e-01],\n",
      "        [2.6230e-01, 8.8346e-01, 3.9650e-01, 9.7011e-01, 8.0028e-01, 7.2706e-02,\n",
      "         1.8863e-01, 1.4509e-01, 9.8381e-01],\n",
      "        [4.7607e-01, 9.8306e-01, 5.0544e-02, 9.9563e-01, 7.9161e-01, 8.0645e-01,\n",
      "         9.9257e-02, 3.0215e-01, 7.9286e-01]]) 2 torch.Size([5, 9])\n"
     ]
    }
   ],
   "source": [
    "data2 = torch.rand(5,9)ﬁ\n",
    "print(data2, data2.dim(), data2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb055db",
   "metadata": {},
   "source": [
    "#### 3D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63717c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0493],\n",
      "         [0.8115]],\n",
      "\n",
      "        [[0.6462],\n",
      "         [0.9108]],\n",
      "\n",
      "        [[0.5997],\n",
      "         [0.9462]]]) 3 torch.Size([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "data3 = torch.rand(3, 2, 1)\n",
    "print(data3, data3.dim(), data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "148d3c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [2.]],\n",
      "\n",
      "        [[3.],\n",
      "         [4.]],\n",
      "\n",
      "        [[5.],\n",
      "         [6.]]]) 3 torch.Size([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "data3 = torch.FloatTensor([[[1],[2]],[[3],[4]],[[5],[6]]])\n",
    "print(data3, data3.dim(), data3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad78af1",
   "metadata": {},
   "source": [
    "### Tensor Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afd4d9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "data = torch.DoubleTensor([[1,2,3],[4,5,6]])\n",
    "print(data, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5aa168b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]], dtype=torch.float64) torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "data = data.reshape(3,2)\n",
    "print(data, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fe7ae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "data = data.reshape(2, -1)\n",
    "print(data, data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a613eca",
   "metadata": {},
   "source": [
    "#### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9711d4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) 2 2 3\n"
     ]
    }
   ],
   "source": [
    "data = torch.DoubleTensor([ \n",
    "    [[1, 2, 3], \n",
    "    [4, 5, 6]],\n",
    "    [[7, 8, 9], \n",
    "    [10, 11, 12]]\n",
    "])\n",
    "print (data.shape, data.size(0), data.size(1), data.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07a462f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]], dtype=torch.float64) torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "data = data.view(3, -1) \n",
    "print (data, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06bd0f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]], dtype=torch.float64) torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "data = data.view(-1, 3)\n",
    "print (data, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d07fca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.],\n",
      "         [ 2.],\n",
      "         [ 3.],\n",
      "         [ 4.]],\n",
      "\n",
      "        [[ 5.],\n",
      "         [ 6.],\n",
      "         [ 7.],\n",
      "         [ 8.]],\n",
      "\n",
      "        [[ 9.],\n",
      "         [10.],\n",
      "         [11.],\n",
      "         [12.]]], dtype=torch.float64) torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "data = data.view(3, 4, -1)\n",
    "print (data, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63221c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]]) 2 torch.Size([4, 1])\n",
      "tensor([1., 2., 3., 4.]) 1 torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "data = torch.FloatTensor([[1], [2], [3], [4]])\n",
    "print(data, data.ndim, data.shape)\n",
    "data1 = torch.squeeze(data)\n",
    "print(data1, data1.ndim, data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88e34dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]]) 2 torch.Size([2, 2])\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]]]) 3 torch.Size([1, 2, 2])\n",
      "tensor([[[1., 2.]],\n",
      "\n",
      "        [[3., 4.]]]) 3 torch.Size([2, 1, 2])\n",
      "tensor([[[1.],\n",
      "         [2.]],\n",
      "\n",
      "        [[3.],\n",
      "         [4.]]]) 3 torch.Size([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "data = torch.FloatTensor([[1,2], [3,4]])\n",
    "print(data, data.ndim, data.shape)\n",
    "data1 = data.unsqueeze(0)\n",
    "print(data1, data1.ndim, data1.shape)\n",
    "data2 = data.unsqueeze(1)\n",
    "print(data2, data2.ndim, data2.shape)\n",
    "data3 = data.unsqueeze(2)\n",
    "print(data3, data3.ndim, data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adbed2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
